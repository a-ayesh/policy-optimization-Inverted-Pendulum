# Hyperparameters for the PPO algorithm
TRAINING_TIMESTEPS = 100000
N_STEPS = 2048
# Optimal hyperparameters
optimal_learning_rate = 0.001
optimal_gamma = 0.99
optimal_clip_range = 0.3
optimal_ent_coef = 0.01
optimal_n_steps = 256

# Number of episodes to evaluate the agent
N_EVAL_EPISODES = 10